import fs from "fs";
import pdfParse from "pdf-parse";  
import * as XLSX from "xlsx";
import axios from "axios";

const LLM_URL = process.env.LLM_URL || "https://llm-uat.105app.site/v1/chat/completions";

/**
 * Simple rule-based extraction (fallback when LLM is unavailable)
 */
function extractWithRules(text) {
  const entities = [];
  const relations = [];
  
  // à¸«à¸²à¸„à¸³à¸ªà¸³à¸„à¸±à¸à¸à¸·à¹‰à¸™à¸à¸²à¸™
  const lines = text.split('\n').filter(l => l.trim().length > 0);
  
  lines.forEach((line, idx) => {
    const trimmed = line.trim();
    
    // à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‡à¹ˆà¸²à¸¢à¹†: à¸«à¸² project name, KPI, target
    if (trimmed.toLowerCase().includes('project') || trimmed.toLowerCase().includes('à¹‚à¸„à¸£à¸‡à¸à¸²à¸£')) {
      entities.push({
        id: `project_${idx}`,
        type: "Project",
        label: trimmed.substring(0, 100),
        lang: "th"
      });
    }
    
    if (trimmed.match(/\d+%/) || trimmed.toLowerCase().includes('kpi')) {
      entities.push({
        id: `kpi_${idx}`,
        type: "KPI",
        label: trimmed.substring(0, 100),
        lang: "th"
      });
    }
  });
  
  return { entities, relations };
}

export async function extractFeaturesFromFile(filePath, fileType) {
  let text = "";

  console.log(`ğŸ“‚ Processing file: ${filePath}`);
  console.log(`ğŸ“‹ File type: ${fileType}`);

  try {
    if (fileType === ".pdf") {
      const dataBuffer = fs.readFileSync(filePath);
      console.log(`ğŸ“¦ PDF buffer size: ${dataBuffer.length} bytes`);
      
      const pdf = await pdfParse(dataBuffer); 
      text = pdf.text || "";
      
      console.log(`ğŸ“„ PDF info: ${pdf.numpages} pages`);
      console.log(`ğŸ“ First 200 chars: ${text.substring(0, 200)}`);
      
    } else if (fileType === ".xls" || fileType === ".xlsx") {
      const workbook = XLSX.readFile(filePath);
      console.log(`ğŸ“Š Excel sheets: ${workbook.SheetNames.join(', ')}`);
      
      const sheet = workbook.Sheets[workbook.SheetNames[0]];
      text = XLSX.utils.sheet_to_csv(sheet);
      
      console.log(`ğŸ“ First 200 chars: ${text.substring(0, 200)}`);
      
    } else {
      throw new Error(`Unsupported file type: ${fileType}`);
    }
  } catch (error) {
    console.error(`âŒ Error reading file: ${error.message}`);
    throw error;
  }

  console.log(`ğŸ“„ Extracted text length: ${text.length} characters`);

  // à¸–à¹‰à¸² text à¸ªà¸±à¹‰à¸™à¹€à¸à¸´à¸™à¹„à¸› à¹à¸ªà¸”à¸‡ warning
  if (text.trim().length < 10) {
    console.warn(`âš ï¸  WARNING: Extracted text is too short (${text.length} chars)`);
    console.warn(`âš ï¸  Text content: "${text}"`);
  }

  // à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ API key à¸«à¸£à¸·à¸­ text à¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸² à¹ƒà¸Šà¹‰ rule-based
  if (!process.env.API_KEY || text.trim().length === 0) {
    console.log("âš ï¸  Using rule-based extraction (no API key or empty text)");
    return extractWithRules(text);
  }

  try {
    // ğŸ”¹ à¹€à¸£à¸µà¸¢à¸ LLM (gpt-oss20b à¸šà¸™ vLLM)
    console.log(`ğŸ¤– Calling LLM at ${LLM_URL}...`);
    const res = await axios.post(
      LLM_URL,
      {
        model: "gpt-oss20b",
        messages: [
          {
            role: "system",
            content: "You are a data extraction expert. You MUST respond ONLY with valid JSON. Do not include any explanations or text outside the JSON structure."
          },
          {
            role: "user",
            content: `Extract entities and relationships from the following text and return ONLY valid JSON in this exact format:
{
  "entities": [
    {"id": "unique_id", "type": "EntityType", "label": "Entity Name", "lang": "en"}
  ],
  "relations": [
    {"subject": "entity_id_1", "predicate": "relationType", "object": "entity_id_2"}
  ]
}

Text to analyze:
${text.substring(0, 4000)}`
          }
        ],
        temperature: 0.3,
        max_tokens: 2000
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.API_KEY}`,
          "Content-Type": "application/json",
        },
        timeout: 30000 // 30 seconds timeout
      }
    );

    // Parse LLM response
    const content = res.data.choices?.[0]?.message?.content || "{}";
    console.log("âœ… LLM Raw Response:", content.substring(0, 200) + "...");
    
    // à¸¥à¸­à¸‡ parse JSON à¸–à¹‰à¸²à¸¡à¸µ markdown code block
    let jsonStr = content.trim();
    if (jsonStr.startsWith("```json")) {
      jsonStr = jsonStr.replace(/^```json\s*/, "").replace(/```\s*$/, "");
    } else if (jsonStr.startsWith("```")) {
      jsonStr = jsonStr.replace(/^```\s*/, "").replace(/```\s*$/, "");
    }
    
    const parsed = JSON.parse(jsonStr);
    console.log(`âœ… Parsed ${parsed.entities?.length || 0} entities, ${parsed.relations?.length || 0} relations`);
    return parsed;
    
  } catch (e) {
    console.error("âŒ LLM Error:", e.message);
    if (e.response) {
      console.error("Response status:", e.response.status);
      console.error("Response data:", e.response.data);
    }
    
    // Fallback to rule-based extraction
    console.log("âš ï¸  Falling back to rule-based extraction");
    return extractWithRules(text);
  }
}


